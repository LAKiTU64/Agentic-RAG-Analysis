# AI Agent LLMæ€§èƒ½åˆ†æå™¨ - é…ç½®æŒ‡å—

## ğŸ“‹ ç›®å½•ç»“æ„

```
Agent/
â”œâ”€â”€ AI agent/
â”‚   â”œâ”€â”€ langchain_version/          # LangChainç‰ˆæœ¬AI Agent (æ¨èä½¿ç”¨)
â”‚   â”‚   â”œâ”€â”€ langchain_agent.py      # LangChain Agentæ ¸å¿ƒ
â”‚   â”‚   â”œâ”€â”€ web_langchain_backend.py # Webåç«¯æœåŠ¡
â”‚   â”‚   â””â”€â”€ start_agent.py          # å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ original_version/           # åŸå§‹ç‰ˆæœ¬AI Agent
â”‚   â”‚   â”œâ”€â”€ ai_agent_analyzer.py    # AI Agentåˆ†æå™¨æ ¸å¿ƒ
â”‚   â”‚   â””â”€â”€ web_agent_backend.py    # Webåç«¯æœåŠ¡
â”‚   â”œâ”€â”€ web_interface/
â”‚   â”‚   â””â”€â”€ static/
â”‚   â”‚       â””â”€â”€ chat.html           # å‰ç«¯èŠå¤©ç•Œé¢
â”‚   â””â”€â”€ configs_and_docs/
â”‚       â””â”€â”€ agent_config.yaml       # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ TOOLS/
â”‚   â””â”€â”€ Auto_Anlyze_tool/           # æ€§èƒ½åˆ†æå·¥å…·
â”‚       â”œâ”€â”€ nsys_parser.py          # NSysè§£æå™¨
â”‚       â”œâ”€â”€ ncu_parser.py           # NCUè§£æå™¨
â”‚       â””â”€â”€ nsys_to_ncu_analyzer.py # é›†æˆåˆ†æå™¨
â”œâ”€â”€ SGlang/                         # SGlangä»£ç ç›®å½• (éœ€è¦è‡ªè¡Œæ”¾ç½®)
â””â”€â”€ workspace/
    â””â”€â”€ models/                     # æ¨¡å‹æ–‡ä»¶ç›®å½• (éœ€è¦è‡ªè¡Œæ”¾ç½®)
```

---

## ğŸ”§ é…ç½®é¡¹è¯´æ˜

### 1ï¸âƒ£ **SGlangæœåŠ¡åœ°å€é…ç½®**

#### ä½ç½®1: `AI agent/configs_and_docs/agent_config.yaml` (ä¸»é…ç½®)

```yaml
defaults:
  # æœåŠ¡å™¨å‚æ•°
  host: "127.0.0.1"     # â† ä¿®æ”¹è¿™é‡Œï¼šSGlangæœåŠ¡çš„IPåœ°å€
  port: 30000            # â† ä¿®æ”¹è¿™é‡Œï¼šSGlangæœåŠ¡çš„ç«¯å£å·
```

**è¯´æ˜**ï¼š
- å¦‚æœSGlangè¿è¡Œåœ¨æœ¬æœºï¼šä¿æŒ `127.0.0.1`
- å¦‚æœSGlangè¿è¡Œåœ¨è¿œç¨‹æœåŠ¡å™¨ï¼šæ”¹ä¸ºæœåŠ¡å™¨IPï¼Œå¦‚ `192.168.1.100`
- ç«¯å£é»˜è®¤30000ï¼Œå¦‚æœSGlangä½¿ç”¨å…¶ä»–ç«¯å£ï¼Œéœ€è¦ç›¸åº”ä¿®æ”¹

#### ä½ç½®2: `AI agent/original_version/ai_agent_analyzer.py`

```python
@dataclass
class AnalysisRequest:
    # é«˜çº§å‚æ•°
    tp_size: int = 1
    host: str = "127.0.0.1"      # â† ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹é»˜è®¤å€¼
    port: int = 30000             # â† ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹é»˜è®¤å€¼
```

**å»ºè®®**ï¼šä¼˜å…ˆä½¿ç”¨ `agent_config.yaml` é…ç½®ï¼Œä»£ç ä¸­çš„æ˜¯é»˜è®¤å€¼ã€‚

---

### 2ï¸âƒ£ **æ¨¡å‹æ–‡ä»¶è·¯å¾„é…ç½®**

#### ä½ç½®1: `AI agent/configs_and_docs/agent_config.yaml` (ä¸»é…ç½®)

```yaml
workspace:
  root_dir: "."
  models_dir: "workspace/models"   # â† ä¿®æ”¹è¿™é‡Œï¼šæ¨¡å‹å­˜æ”¾ç›®å½•
  sglang_dir: "SGlang"             # â† ä¿®æ”¹è¿™é‡Œï¼šSGlangä»£ç ç›®å½•
  tools_dir: "TOOLS/Auto_Anlyze_tool"

# æ¨¡å‹é…ç½®æ˜ å°„
model_mappings:
  # æ¨¡å‹åˆ«å -> å®é™…è·¯å¾„çš„æ˜ å°„
  "llama-7b": "meta-llama/Llama-2-7b-hf"   # â† ä¿®æ”¹è¿™é‡Œï¼šå¯ä»¥æ”¹ä¸ºæœ¬åœ°è·¯å¾„
  "llama-13b": "meta-llama/Llama-2-13b-hf"
  "qwen-7b": "Qwen/Qwen-7B-Chat"
  "qwen-14b": "Qwen/Qwen-14B-Chat"
  "chatglm-6b": "THUDM/chatglm-6b"
```

**è¯´æ˜**ï¼š
- `models_dir`ï¼šå­˜æ”¾æ¨¡å‹æ–‡ä»¶çš„ç›®å½•ï¼Œå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
- `model_mappings`ï¼šæ¨¡å‹åˆ«ååˆ°å®é™…è·¯å¾„çš„æ˜ å°„
  - å¦‚æœæ¨¡å‹åœ¨æœ¬åœ°ï¼š`"llama-7b": "D:/Models/llama-7b"` (ç»å¯¹è·¯å¾„)
  - å¦‚æœæ¨¡å‹åœ¨workspaceä¸‹ï¼š`"llama-7b": "workspace/models/llama-7b"` (ç›¸å¯¹è·¯å¾„)
  - å¦‚æœä½¿ç”¨HuggingFace IDï¼šä¿æŒåŸæ ·ï¼Œå¦‚ `"meta-llama/Llama-2-7b-hf"`

#### ä½ç½®2: `AI agent/original_version/ai_agent_analyzer.py`

```python
class ConfigGenerator:
    def __init__(self, workspace_root: str = "."):
        self.workspace_root = Path(workspace_root)
        self.models_dir = self.workspace_root / "workspace" / "models"  # â† æ¨¡å‹ç›®å½•
```

**æ¨¡å‹è·¯å¾„è§£æé€»è¾‘**ï¼š
1. å¦‚æœæä¾›ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
2. å¦åˆ™åœ¨ `workspace/models/` ä¸‹æŸ¥æ‰¾
3. å¦‚æœæœ¬åœ°æ‰¾ä¸åˆ°ï¼Œå‡è®¾æ˜¯HuggingFaceæ¨¡å‹ID

---

### 3ï¸âƒ£ **SGlangç›®å½•é…ç½®**

**é‡è¦**ï¼šSGlangç›®å½•éœ€è¦ä½ è‡ªå·±å‡†å¤‡ï¼

```bash
# å…‹éš†SGlangä»“åº“åˆ°é¡¹ç›®æ ¹ç›®å½•
cd D:/Desk/Xiong/Agent
git clone https://github.com/sgl-project/sglang.git SGlang

# æˆ–è€…å¦‚æœå·²ç»æœ‰SGlangï¼Œå¯ä»¥å»ºç«‹ç¬¦å·é“¾æ¥
# Windows (ç®¡ç†å‘˜æƒé™):
mklink /D SGlang "D:\path\to\your\sglang"
# Linux/Mac:
ln -s /path/to/your/sglang SGlang
```

é…ç½®ä½ç½®ï¼š`agent_config.yaml`
```yaml
workspace:
  sglang_dir: "SGlang"  # â† SGlangä»£ç ç›®å½•
```

---

### 4ï¸âƒ£ **å‰ç«¯æœåŠ¡åœ°å€é…ç½®**

å‰ç«¯æ–‡ä»¶ï¼š`AI agent/web_interface/static/chat.html`

```javascript
// WebSocketè¿æ¥åœ°å€ (ç¬¬546è¡Œé™„è¿‘)
function initWebSocket() {
    const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
    const wsUrl = `${protocol}//${location.host}/ws/${sessionId}`;
    // â†‘ è‡ªåŠ¨ä½¿ç”¨å½“å‰é¡µé¢çš„hostï¼Œé€šå¸¸ä¸éœ€è¦ä¿®æ”¹
}

// æ–‡ä»¶ä¸Šä¼ æ¥å£ (ç¬¬834è¡Œé™„è¿‘)
const response = await fetch('/upload_config', {
    method: 'POST',
    body: formData
});
// â†‘ ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œä¼šè‡ªåŠ¨è¿æ¥åˆ°åç«¯æœåŠ¡å™¨
```

**è¯´æ˜**ï¼š
- å¦‚æœå‰ç«¯å’Œåç«¯åœ¨åŒä¸€æœåŠ¡å™¨ï¼šä¸éœ€è¦ä¿®æ”¹
- å¦‚æœå‰åç«¯åˆ†ç¦»éƒ¨ç½²ï¼šéœ€è¦ä¿®æ”¹ä¸ºå®Œæ•´URL
  ```javascript
  const wsUrl = `ws://192.168.1.100:8000/ws/${sessionId}`;
  const response = await fetch('http://192.168.1.100:8000/upload_config', {...});
  ```

---

## ğŸš€ å¯åŠ¨æµç¨‹

### æ–¹æ³•1: ä½¿ç”¨LangChainç‰ˆæœ¬ (æ¨è)

```bash
# 1. è¿›å…¥langchain_versionç›®å½•
cd "AI agent/langchain_version"

# 2. å¯åŠ¨WebæœåŠ¡
python web_langchain_backend.py

# 3. è®¿é—®å‰ç«¯
# æµè§ˆå™¨æ‰“å¼€: http://localhost:8000/chat
```

### æ–¹æ³•2: ä½¿ç”¨å¯åŠ¨è„šæœ¬

```bash
cd "AI agent/langchain_version"
python start_agent.py --version langchain --port 8000
```

### æ–¹æ³•3: ä½¿ç”¨åŸå§‹ç‰ˆæœ¬

```bash
cd "AI agent/original_version"
python web_agent_backend.py
```

---

## âœ… å¯åŠ¨å‰æ£€æŸ¥æ¸…å•

### å¿…éœ€é¡¹ï¼š

- [ ] **NVIDIAé©±åŠ¨å·²å®‰è£…** (`nvidia-smi` èƒ½æ­£å¸¸è¿è¡Œ)
- [ ] **nsyså·²å®‰è£…** (`nsys --version` èƒ½æ­£å¸¸è¿è¡Œ)
- [ ] **ncuå·²å®‰è£…** (`ncu --version` èƒ½æ­£å¸¸è¿è¡Œ)
- [ ] **PythonåŒ…å·²å®‰è£…** (è§ä¸‹æ–¹ä¾èµ–å®‰è£…)

### å¯é€‰é¡¹ï¼š

- [ ] **SGlangå·²é…ç½®** (å¦‚æœè¦è¿è¡Œæ€§èƒ½åˆ†æ)
- [ ] **æ¨¡å‹å·²ä¸‹è½½** (å¦‚æœè¦åˆ†æç‰¹å®šæ¨¡å‹)

---

## ğŸ“¦ ä¾èµ–å®‰è£…

```bash
# å®‰è£…Pythonä¾èµ–
pip install fastapi uvicorn websockets
pip install pandas matplotlib seaborn numpy
pip install pyyaml requests
pip install langchain langchain-openai langchain-community

# æˆ–ä½¿ç”¨requirementsæ–‡ä»¶
pip install -r "AI agent/configs_and_docs/requirements_web.txt"
```

---

## ğŸ” æµ‹è¯•é…ç½®

### æµ‹è¯•1: åç«¯å¥åº·æ£€æŸ¥

```bash
# å¯åŠ¨åç«¯åï¼Œè®¿é—®:
curl http://localhost:8000/health
```

é¢„æœŸè¾“å‡ºï¼š
```json
{
  "status": "healthy",
  "timestamp": "2025-01-13T10:00:00",
  "active_sessions": 0,
  "langchain_agent_ready": true
}
```

### æµ‹è¯•2: å‰ç«¯è®¿é—®

æµè§ˆå™¨æ‰“å¼€ï¼š`http://localhost:8000/chat`

åº”è¯¥çœ‹åˆ°èŠå¤©ç•Œé¢ï¼ŒçŠ¶æ€æ˜¾ç¤º"å·²è¿æ¥"ï¼ˆç»¿è‰²åœ†ç‚¹ï¼‰

### æµ‹è¯•3: å‘é€æµ‹è¯•æ¶ˆæ¯

åœ¨èŠå¤©æ¡†è¾“å…¥ï¼š
```
åˆ†æ llama-7b æ¨¡å‹ï¼Œbatch_size=8
```

AIåº”è¯¥å›å¤è§£æçš„å‚æ•°ä¿¡æ¯ã€‚

---

## ğŸ› å¸¸è§é—®é¢˜

### é—®é¢˜1: WebSocketè¿æ¥å¤±è´¥

**ç—‡çŠ¶**ï¼šå‰ç«¯æ˜¾ç¤º"è¿æ¥æ–­å¼€"

**è§£å†³**ï¼š
1. æ£€æŸ¥åç«¯æ˜¯å¦æ­£å¸¸è¿è¡Œ
2. æ£€æŸ¥é˜²ç«å¢™æ˜¯å¦é˜»æ­¢8000ç«¯å£
3. æŸ¥çœ‹æµè§ˆå™¨æ§åˆ¶å°çš„é”™è¯¯ä¿¡æ¯

### é—®é¢˜2: æ‰¾ä¸åˆ°æ¨¡å‹

**ç—‡çŠ¶**ï¼šæç¤º "æœªèƒ½ä»æç¤ºè¯ä¸­æå–æ¨¡å‹åç§°"

**è§£å†³**ï¼š
1. ç¡®ä¿æç¤ºè¯åŒ…å«æ¨¡å‹åç§°ï¼Œå¦‚ "llama-7b"
2. æ£€æŸ¥ `agent_config.yaml` ä¸­çš„ `model_mappings`
3. ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨äº `workspace/models/` ç›®å½•

### é—®é¢˜3: SGlangå‘½ä»¤æ‰§è¡Œå¤±è´¥

**ç—‡çŠ¶**ï¼šåˆ†ææ—¶æŠ¥é”™ "nsysåˆ†æå¤±è´¥"

**è§£å†³**ï¼š
1. ç¡®ä¿ `SGlang/` ç›®å½•å­˜åœ¨ä¸”åŒ…å«æ­£ç¡®çš„SGlangä»£ç 
2. ç¡®ä¿SGlangçš„PythonåŒ…å·²å®‰è£…
3. å°è¯•æ‰‹åŠ¨è¿è¡ŒSGlangå‘½ä»¤æµ‹è¯•

### é—®é¢˜4: å¯¼å…¥é”™è¯¯

**ç—‡çŠ¶**ï¼š`ImportError: cannot import name 'xxx'`

**è§£å†³**ï¼š
1. æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•è¿è¡Œ
2. ç¡®ä¿å·²è¿è¡Œé¡¹ç›®æ ¹ç›®å½•çš„ä¿®å¤è„šæœ¬ (è§ä¸‹ä¸€èŠ‚)

---

## ğŸ”¨ æ–‡ä»¶è·¯å¾„ä¿®å¤

æˆ‘å·²ä¸ºä½ åˆ›å»ºäº†è·¯å¾„ä¿®å¤è„šæœ¬ï¼Œè¿è¡Œï¼š

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
python ä¿®å¤æ–‡ä»¶è·¯å¾„.py
```

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. å¤åˆ¶é™æ€æ–‡ä»¶åˆ°æ­£ç¡®ä½ç½®
2. ä¿®å¤å¯¼å…¥è·¯å¾„
3. åˆ›å»ºå¿…è¦çš„ç›®å½•

---

## ğŸ“ é…ç½®ç¤ºä¾‹

### ç¤ºä¾‹1: æœ¬åœ°æ¨¡å‹ + æœ¬åœ°SGlang

`agent_config.yaml`:
```yaml
workspace:
  models_dir: "D:/Models"          # æ¨¡å‹åœ¨Dç›˜
  sglang_dir: "D:/Code/sglang"     # SGlangåœ¨Dç›˜

defaults:
  host: "127.0.0.1"                # æœ¬åœ°è¿è¡Œ
  port: 30000

model_mappings:
  "llama-7b": "D:/Models/Llama-2-7b-hf"
  "qwen-14b": "D:/Models/Qwen-14B-Chat"
```

### ç¤ºä¾‹2: è¿œç¨‹SGlangæœåŠ¡å™¨

`agent_config.yaml`:
```yaml
defaults:
  host: "192.168.1.100"            # è¿œç¨‹æœåŠ¡å™¨IP
  port: 30000

model_mappings:
  "llama-7b": "/data/models/llama-7b"  # æœåŠ¡å™¨ä¸Šçš„è·¯å¾„
```

---

## ğŸ“ æ”¯æŒ

å¦‚æœé‡åˆ°å…¶ä»–é—®é¢˜ï¼š
1. æ£€æŸ¥æ—¥å¿—è¾“å‡º
2. æŸ¥çœ‹ `agent_config.yaml` é…ç½®
3. ç¡®è®¤ç¯å¢ƒä¾èµ–å·²å®‰è£…

