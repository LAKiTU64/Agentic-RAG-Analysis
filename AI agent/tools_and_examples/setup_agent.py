#!/usr/bin/env python3
"""
AI Agentç¯å¢ƒè®¾ç½®è„šæœ¬

è‡ªåŠ¨æ£€æŸ¥å’Œè®¾ç½®AI Agentè¿è¡Œç¯å¢ƒ
"""

import os
import sys
import subprocess
import shutil
from pathlib import Path

def check_command_exists(command):
    """æ£€æŸ¥å‘½ä»¤æ˜¯å¦å­˜åœ¨"""
    return shutil.which(command) is not None

def check_python_package(package):
    """æ£€æŸ¥PythonåŒ…æ˜¯å¦å·²å®‰è£…"""
    try:
        __import__(package)
        return True
    except ImportError:
        return False

def create_directory_structure():
    """åˆ›å»ºæ¨èçš„ç›®å½•ç»“æ„"""
    
    directories = [
        "workspace",
        "workspace/models", 
        "analysis_results",
        "TOOLS/Auto_Anlyze_tool"
    ]
    
    print("ğŸ“ åˆ›å»ºç›®å½•ç»“æ„...")
    for dir_path in directories:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"  âœ… {dir_path}")
    
    # åˆ›å»ºæ¨¡å‹ç›®å½•çš„README
    models_readme = Path("workspace/models/README.md")
    if not models_readme.exists():
        models_readme.write_text("""# æ¨¡å‹ç›®å½•

è¯·å°†LLMæ¨¡å‹æ–‡ä»¶æ”¾ç½®åœ¨æ­¤ç›®å½•ä¸‹ã€‚

## æ”¯æŒçš„æ¨¡å‹æ ¼å¼
- HuggingFaceæ ¼å¼æ¨¡å‹
- æœ¬åœ°æ¨¡å‹æ–‡ä»¶

## ç›®å½•ç»“æ„ç¤ºä¾‹
```
models/
â”œâ”€â”€ llama-7b/
â”œâ”€â”€ qwen-14b/
â””â”€â”€ chatglm-6b/
```

## æ¨¡å‹ä¸‹è½½ç¤ºä¾‹
```bash
# ä½¿ç”¨HuggingFace Hub
huggingface-cli download meta-llama/Llama-2-7b-hf --local-dir llama-7b

# ä½¿ç”¨Git LFS
git lfs clone https://huggingface.co/meta-llama/Llama-2-7b-hf llama-7b
```
""")

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒä¾èµ–"""
    
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒä¾èµ–...")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    print(f"  Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    if python_version < (3, 8):
        print("  âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œå»ºè®®3.8+")
        return False
    else:
        print("  âœ… Pythonç‰ˆæœ¬æ»¡è¶³è¦æ±‚")
    
    # æ£€æŸ¥å¿…éœ€çš„å‘½ä»¤
    required_commands = {
        "nsys": "NVIDIA Nsight Systems",
        "ncu": "NVIDIA Nsight Compute", 
        "python": "Pythonè§£é‡Šå™¨",
        "pip": "PythonåŒ…ç®¡ç†å™¨"
    }
    
    missing_commands = []
    for command, description in required_commands.items():
        if check_command_exists(command):
            print(f"  âœ… {command} ({description})")
        else:
            print(f"  âŒ {command} ({description}) - æœªæ‰¾åˆ°")
            missing_commands.append(command)
    
    # æ£€æŸ¥PythonåŒ…
    required_packages = [
        "pandas", "matplotlib", "seaborn", "numpy", "requests"
    ]
    
    missing_packages = []
    for package in required_packages:
        if check_python_package(package):
            print(f"  âœ… {package}")
        else:
            print(f"  âŒ {package} - æœªå®‰è£…")
            missing_packages.append(package)
    
    return len(missing_commands) == 0 and len(missing_packages) == 0

def install_python_requirements():
    """å®‰è£…Pythonä¾èµ–"""
    
    requirements = [
        "pandas>=1.3.0",
        "matplotlib>=3.5.0", 
        "seaborn>=0.11.0",
        "numpy>=1.21.0",
        "requests>=2.25.0",
        "pyyaml>=5.4.0"
    ]
    
    print("ğŸ“¦ å®‰è£…Pythonä¾èµ–...")
    
    # åˆ›å»ºrequirements.txt
    requirements_file = Path("requirements_agent.txt")
    requirements_file.write_text("\n".join(requirements))
    print(f"  ğŸ“ å·²ç”Ÿæˆ {requirements_file}")
    
    # å®‰è£…ä¾èµ–
    try:
        subprocess.run([
            sys.executable, "-m", "pip", "install", "-r", str(requirements_file)
        ], check=True)
        print("  âœ… Pythonä¾èµ–å®‰è£…å®Œæˆ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"  âŒ å®‰è£…å¤±è´¥: {e}")
        return False

def setup_analysis_tools():
    """è®¾ç½®åˆ†æå·¥å…·"""
    
    tools_dir = Path("TOOLS/Auto_Anlyze_tool")
    
    # æ£€æŸ¥åˆ†æè„šæœ¬æ˜¯å¦å­˜åœ¨
    required_scripts = [
        "nsys_parser.py",
        "ncu_parser.py", 
        "nsys_to_ncu_analyzer.py"
    ]
    
    print("ğŸ”§ æ£€æŸ¥åˆ†æå·¥å…·...")
    
    missing_scripts = []
    for script in required_scripts:
        script_path = tools_dir / script
        if script_path.exists():
            print(f"  âœ… {script}")
        else:
            print(f"  âŒ {script} - æœªæ‰¾åˆ°")
            missing_scripts.append(script)
    
    if missing_scripts:
        print("  âš ï¸  è¯·ç¡®ä¿åˆ†æå·¥å…·è„šæœ¬å·²æ­£ç¡®æ”¾ç½®åœ¨ TOOLS/Auto_Anlyze_tool/ ç›®å½•ä¸‹")
        return False
    
    return True

def check_gpu_environment():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    
    print("ğŸ–¥ï¸  æ£€æŸ¥GPUç¯å¢ƒ...")
    
    try:
        # æ£€æŸ¥nvidia-smi
        result = subprocess.run(["nvidia-smi"], capture_output=True, text=True, check=True)
        print("  âœ… NVIDIA GPUé©±åŠ¨æ­£å¸¸")
        
        # å°è¯•æå–GPUä¿¡æ¯
        lines = result.stdout.split('\n')
        gpu_lines = [line for line in lines if 'GeForce' in line or 'Tesla' in line or 'Quadro' in line or 'A100' in line or 'H100' in line]
        
        for gpu_line in gpu_lines[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªGPU
            gpu_info = gpu_line.split('|')[1].strip() if '|' in gpu_line else gpu_line.strip()
            print(f"    ğŸ“± {gpu_info}")
        
        return True
        
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("  âŒ æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–é©±åŠ¨æœªæ­£ç¡®å®‰è£…")
        return False

def create_example_config():
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    
    print("ğŸ“„ åˆ›å»ºç¤ºä¾‹æ–‡ä»¶...")
    
    # åˆ›å»ºç¤ºä¾‹å¯åŠ¨è„šæœ¬
    start_script = Path("start_agent.py")
    if not start_script.exists():
        start_script.write_text("""#!/usr/bin/env python3
\"\"\"
AI Agentå¿«é€Ÿå¯åŠ¨è„šæœ¬
\"\"\"

from ai_agent_analyzer import AIAgentAnalyzer

def main():
    print("ğŸ¤– AI Agent LLMæ€§èƒ½åˆ†æå™¨")
    print("=" * 40)
    
    agent = AIAgentAnalyzer(workspace_root=".")
    
    while True:
        try:
            prompt = input("\\nğŸ’¬ è¯·è¾“å…¥åˆ†æéœ€æ±‚ (è¾“å…¥'quit'é€€å‡º): ").strip()
            
            if prompt.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§!")
                break
            
            if not prompt:
                continue
            
            print("\\nğŸ”„ å¼€å§‹åˆ†æ...")
            results = agent.analyze_from_prompt(prompt)
            
            if 'error' not in results:
                print("âœ… åˆ†æå®Œæˆ!")
                if 'request' in results:
                    output_dir = results['request'].get('output_dir', 'N/A')
                    print(f"ğŸ“ ç»“æœç›®å½•: {output_dir}")
            else:
                print(f"âŒ åˆ†æå¤±è´¥: {results['error']}")
                
        except KeyboardInterrupt:
            print("\\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"âŒ æ„å¤–é”™è¯¯: {e}")

if __name__ == "__main__":
    main()
""")
        print(f"  âœ… {start_script}")
    
    # åˆ›å»ºæ¨¡å‹é…ç½®ç¤ºä¾‹
    model_config = Path("model_config_example.py")
    if not model_config.exists():
        model_config.write_text("""# æ¨¡å‹é…ç½®ç¤ºä¾‹

# å¸¸è§çš„æç¤ºè¯ç¤ºä¾‹
EXAMPLE_PROMPTS = [
    # åŸºç¡€åˆ†æ
    "åˆ†æ llama-7b æ¨¡å‹ï¼Œbatch_size=8",
    "å¯¹ qwen-14b è¿›è¡Œ nsys å…¨å±€æ€§èƒ½åˆ†æ",
    "ç»¼åˆåˆ†æ chatglm-6b çš„æ€§èƒ½ç“¶é¢ˆ",
    
    # è‡ªå®šä¹‰å‚æ•°
    "åˆ†æ baichuan-13bï¼Œbatch_size=1,4,8ï¼Œinput_len=512,1024",
    "å¯¹ vicuna-7b è¿›è¡Œ ncu kernelæ·±åº¦åˆ†æï¼Œtemperature=0.1",
    
    # è‹±æ–‡æç¤ºè¯
    "analyze llama-7b with batch_size=16, input_len=1024",
    "ncu analysis for qwen-14b model with tp_size=2"
]

# æ¨¡å‹è·¯å¾„æ˜ å°„ (å¦‚æœä½¿ç”¨æœ¬åœ°æ¨¡å‹)
MODEL_PATHS = {
    "llama-7b": "workspace/models/llama-7b",
    "qwen-14b": "workspace/models/qwen-14b", 
    "chatglm-6b": "workspace/models/chatglm-6b"
}

# å¸¸ç”¨é…ç½®
DEFAULT_CONFIGS = {
    "small_model": {
        "batch_size": [1, 4, 8],
        "input_len": [256, 512],
        "output_len": [32, 64]
    },
    "large_model": {
        "batch_size": [1, 2, 4], 
        "input_len": [512, 1024],
        "output_len": [64, 128]
    }
}
""")
        print(f"  âœ… {model_config}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AI Agentç¯å¢ƒè®¾ç½®å‘å¯¼")
    print("=" * 50)
    
    success = True
    
    # 1. åˆ›å»ºç›®å½•ç»“æ„
    create_directory_structure()
    
    # 2. æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        print("\nâš ï¸  å‘ç°ç¯å¢ƒé—®é¢˜ï¼Œå°è¯•ä¿®å¤...")
        success = install_python_requirements() and success
    
    # 3. æ£€æŸ¥GPUç¯å¢ƒ
    gpu_ok = check_gpu_environment()
    if not gpu_ok:
        print("  âš ï¸  GPUç¯å¢ƒå¯èƒ½æœ‰é—®é¢˜ï¼Œä½†ä¸å½±å“åŸºç¡€åŠŸèƒ½")
    
    # 4. è®¾ç½®åˆ†æå·¥å…·
    tools_ok = setup_analysis_tools()
    success = tools_ok and success
    
    # 5. åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
    create_example_config()
    
    print("\n" + "=" * 50)
    
    if success:
        print("âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ!")
        print("\nğŸ“‹ åç»­æ­¥éª¤:")
        print("1. å°†æ¨¡å‹æ–‡ä»¶æ”¾å…¥ workspace/models/ ç›®å½•")
        print("2. ç¡®ä¿ TOOLS/Auto_Anlyze_tool/ åŒ…å«åˆ†æè„šæœ¬")
        print("3. è¿è¡Œ: python start_agent.py")
        print("4. æˆ–ä½¿ç”¨: python ai_agent_analyzer.py interactive")
        
        print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
        print('python ai_agent_analyzer.py prompt "åˆ†æ llama-7bï¼Œbatch_size=8"')
        
    else:
        print("âŒ ç¯å¢ƒè®¾ç½®é‡åˆ°é—®é¢˜!")
        print("\nğŸ”§ æ‰‹åŠ¨æ£€æŸ¥:")
        print("1. å®‰è£…NVIDIA Nsight Systemså’ŒCompute")
        print("2. è¿è¡Œ: pip install -r requirements_agent.txt") 
        print("3. ç¡®ä¿åˆ†æå·¥å…·è„šæœ¬å­˜åœ¨")
    
    print(f"\nğŸ“ å·¥ä½œç›®å½•: {Path.cwd()}")

if __name__ == "__main__":
    main()

