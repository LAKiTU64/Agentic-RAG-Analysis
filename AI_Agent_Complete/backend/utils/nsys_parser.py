#!/usr/bin/env python3
"""
NVIDIA Nsight Systems (nsys) è¾“å‡ºæ–‡ä»¶è‡ªåŠ¨åŒ–è§£æžå·¥å…·
"""
from pathlib import Path
from typing import Dict, List, Optional, Union, Tuple
from dataclasses import dataclass
from datetime import datetime

import sqlite3
import csv
import subprocess

@dataclass
class KernelInfo:
    name: str
    start_ns: int
    end_ns: int
    duration_ns: int
    layer: Optional[str] = None
    grid: Optional[Tuple[int,int,int]] = None
    block: Optional[Tuple[int,int,int]] = None
    regs_per_thread: Optional[int] = None
    shared_mem: Optional[int] = None

class NsysParser:
    """Nsys è¾“å‡ºæ–‡ä»¶è§£æžå™¨"""
    def __init__(self, input_file: str):
        self.input_file = Path(input_file)
        self.sqlite_file: Optional[Path] = None
        if self.input_file.suffix == '.sqlite':
            self.sqlite_file = self.input_file
        elif self.input_file.suffix == '.nsys-rep':
            self.sqlite_file = self.input_file.with_suffix('.sqlite')

        self.tables: List[str] = []
        self.kernels: List[KernelInfo] = []
        self.layer_kernel_rows: List[Dict[str, Union[str, float]]] = []
        self.string_map: Dict[int, str] = {}

    def parse(self) -> None:
        # è‹¥è¾“å…¥æ˜¯ .nsys-repï¼Œåˆ™å…ˆå¯¼å‡ºä¸º .sqlite
        if self.input_file.suffix == '.nsys-rep':
            self._parse_nsys_rep()
            return
        # ç›´æŽ¥è§£æž .sqlite
        if not self.sqlite_file or not Path(self.sqlite_file).exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ° SQLite æ–‡ä»¶: {self.sqlite_file or self.input_file}")
        self._parse_sqlite(self.sqlite_file)

    def _parse_nsys_rep(self) -> None:
        """è§£æž .nsys-rep æ–‡ä»¶ï¼ˆå…ˆå¯¼å‡ºä¸ºSQLiteï¼‰"""
        print("ðŸ“‹ æ£€æµ‹åˆ° .nsys-rep æ–‡ä»¶ï¼Œæ­£åœ¨å¯¼å‡ºä¸ºSQLiteæ ¼å¼...")
        sqlite_file = self.input_file.with_suffix('.sqlite')
        cmd = [
            'nsys', 'export',
            '--type=sqlite',
            '--force-overwrite=true',
            '--output', str(sqlite_file),
            str(self.input_file)
        ]
        try:
            subprocess.run(cmd, capture_output=True, text=True, check=True)
            print(f"âœ… å¯¼å‡ºæˆåŠŸ: {sqlite_file}")
            self.sqlite_file = sqlite_file
            self._parse_sqlite(sqlite_file)
        except subprocess.CalledProcessError as e:
            print(f"âŒ nsyså¯¼å‡ºå¤±è´¥: {e.stderr}")
            print("è¯·ç¡®ä¿ nsys å·¥å…·å·²æ­£ç¡®å®‰è£…å¹¶åœ¨PATHä¸­")
            raise
        except FileNotFoundError:
            print("âŒ æœªæ‰¾åˆ° nsys å‘½ä»¤")
            print("è¯·å®‰è£… NVIDIA Nsight Systems å¹¶ç¡®ä¿ nsys åœ¨PATHä¸­")
            raise

    def _parse_sqlite(self, sqlite_file: Optional[Path] = None) -> None:
        conn = sqlite3.connect(str(sqlite_file))
        try:
            self.tables = self._get_table_names(conn)
            self._load_string_ids(conn)
            self._parse_cuda_kernels(conn)
            self.layer_kernel_rows = self._query_layer_kernels(conn)
            # å¯¼å‡º layer_kernels.csv åˆ° SQLite åŒç›®å½•
            out_csv = Path(str(sqlite_file)).with_name('layer_kernels.csv')
            if self.layer_kernel_rows:
                with open(out_csv, 'w', encoding='utf-8', newline='') as f:
                    w = csv.DictWriter(f, fieldnames=['layer', 'kernel_name', 'dur_ms'])
                    w.writeheader()
                    w.writerows(self.layer_kernel_rows)
        finally:
            conn.close()

    def _get_table_names(self, conn: sqlite3.Connection) -> List[str]:
        cur = conn.cursor()
        cur.execute("SELECT name FROM sqlite_master WHERE type='table';")
        return [r[0] for r in cur.fetchall()]

    def _load_string_ids(self, conn: sqlite3.Connection) -> None:
        """åŠ è½½ StringIds æ˜ å°„ï¼šid -> value"""
        self.string_map = {}
        if 'StringIds' not in self.tables:
            print("âš  StringIds è¡¨ä¸å­˜åœ¨ï¼Œæ— æ³•è§£ç åç§°ã€‚")
            return
        cur = conn.cursor()
        try:
            cur.execute("SELECT id, value FROM StringIds;")
            self.string_map = dict(cur.fetchall())
            print(f"ðŸ”  StringIds åŠ è½½æˆåŠŸï¼Œå…± {len(self.string_map)} æ¡ã€‚")
        except Exception as e:
            print(f"âš  è¯»å– StringIds å¤±è´¥: {e}")

    def _parse_cuda_kernels(self, conn: sqlite3.Connection) -> None:
        """è§£æžCUDA kernelä¿¡æ¯ï¼ˆè§£ç  kernel åç§° + ç»“æž„åŒ–å­—æ®µï¼‰"""
        print("ðŸ§© æ­£åœ¨è§£æž CUDA kernels å¹¶è§£ç  kernel åç§°...")
        kernel_tables = [t for t in self.tables if t.upper().startswith('CUPTI_ACTIVITY_KIND') and 'KERNEL' in t.upper()]
        if not kernel_tables:
            print("âš  æœªæ‰¾åˆ° CUPTI kernel è¡¨ã€‚")
            return
        ktable = kernel_tables[0]
        cur = conn.cursor()
        cur.execute(f"PRAGMA table_info({ktable});")
        cols = {row[1] for row in cur.fetchall()}
        if not {'start', 'end'}.issubset(cols):
            print("âš  CUPTI kernel è¡¨ç¼ºå°‘ start/end åˆ—ã€‚")
            return
        name_col = 'demangledName' if 'demangledName' in cols else ('name' if 'name' in cols else None)
        if not name_col:
            print("âš  CUPTI kernel è¡¨ç¼ºå°‘åç§°åˆ—ï¼ˆdemangledName/nameï¼‰ã€‚")
            return

        query = f"""
        SELECT 
            {name_col} as name_id,
            start,
            end,
            (end - start) as dur_ns,
            gridX, gridY, gridZ,
            blockX, blockY, blockZ,
            registersPerThread,
            sharedMemoryExecuted
        FROM {ktable}
        ORDER BY start
        """
        cur.execute(query)
        rows = cur.fetchall()

        for r in rows:
            name_id = r[0]
            kernel_name = self.string_map.get(name_id) if isinstance(name_id, int) else (str(name_id) if name_id is not None else "Unknown Kernel")
            self.kernels.append(KernelInfo(
                name=kernel_name or "Unknown Kernel",
                start_ns=int(r[1]),
                end_ns=int(r[2]),
                duration_ns=int(r[3]),
                grid=(r[4], r[5], r[6]) if r[4] is not None else None,
                block=(r[7], r[8], r[9]) if r[7] is not None else None,
                regs_per_thread=r[10],
                shared_mem=r[11],
            ))
        print(f"ðŸ”¥ è§£æžåˆ° {len(self.kernels)} ä¸ª CUDA kernelsï¼ˆå·²è§£ç åç§°ï¼‰")

    def _query_layer_kernels(self, conn: sqlite3.Connection) -> List[Dict]:
        """ä¸‰è¡¨ JOINï¼šNVTX_EVENTS + StringIds + CUPTI kernelï¼Œç”Ÿæˆ layer_kernels"""
        if 'NVTX_EVENTS' not in self.tables or 'StringIds' not in self.tables:
            return []
        kernel_tables = [t for t in self.tables if t.upper().startswith('CUPTI_ACTIVITY_KIND') and 'KERNEL' in t.upper()]
        if not kernel_tables:
            return []
        ktable = kernel_tables[0]
        cur = conn.cursor()
        cur.execute(f"PRAGMA table_info({ktable});")
        cols = {row[1] for row in cur.fetchall()}

        def _find_col(candidates: Tuple[str, ...], available: set) -> Optional[str]:
            lower_map = {c.lower(): c for c in available}
            for cand in candidates:
                if cand in available:
                    return cand
                if cand.lower() in lower_map:
                    return lower_map[cand.lower()]
            return None

        start_col = _find_col(("start",), cols)
        end_col = _find_col(("end",), cols)
        if not (start_col and end_col):
            print("âš  layer_kernels æŸ¥è¯¢å¤±è´¥: CUPTI kernel è¡¨ä¸å« end/start åˆ—")
            return []
        name_col = _find_col(("demangledName", "name"), cols)
        if not name_col:
            print("âš  layer_kernels æŸ¥è¯¢å¤±è´¥: ç¼ºå°‘åç§°åˆ—")
            return []

        runtime_tables = [t for t in self.tables if t.upper().startswith('CUPTI_ACTIVITY_KIND_RUNTIME')]
        runtime_table = runtime_tables[0] if runtime_tables else None

        nvtx_cur = conn.cursor()
        nvtx_cur.execute("PRAGMA table_info(NVTX_EVENTS);")
        nvtx_cols = {row[1] for row in nvtx_cur.fetchall()}

        corr_col = _find_col(("correlationId", "correlation_id"), cols)
        nvtx_corr_col = _find_col(("correlationId", "correlation_id"), nvtx_cols)

        def _nvtx_layer_expr(alias: str = "n") -> Tuple[str, str]:
            text_id_col = _find_col(("textId", "text_id"), nvtx_cols)
            text_col = _find_col(("text",), nvtx_cols)
            if text_id_col:
                if text_col:
                    return (f"LEFT JOIN StringIds s ON {alias}.{text_id_col} = s.id", f"COALESCE({alias}.{text_col}, s.value)")
                return (f"LEFT JOIN StringIds s ON {alias}.{text_id_col} = s.id", "s.value")
            if text_col:
                return ("", f"{alias}.{text_col}")
            return ("", "'Unknown Layer'")

        runtime_corr_col = None
        runtime_start_col = None
        runtime_end_col = None
        runtime_tid_col = None
        if runtime_table:
            rt_cur = conn.cursor()
            rt_cur.execute(f"PRAGMA table_info({runtime_table});")
            rt_cols = {row[1] for row in rt_cur.fetchall()}
            runtime_corr_col = _find_col(("correlationId", "correlation_id"), rt_cols)
            runtime_start_col = _find_col(("start",), rt_cols)
            runtime_end_col = _find_col(("end",), rt_cols)
            runtime_tid_col = _find_col(("globalTid", "global_tid", "globalThreadId"), rt_cols)

        nvtx_start_col = _find_col(("start",), nvtx_cols)
        nvtx_end_col = _find_col(("end",), nvtx_cols)
        nvtx_tid_col = _find_col(("globalTid", "global_tid", "globalThreadId"), nvtx_cols)

        use_four_join = all([runtime_table, corr_col, runtime_corr_col, runtime_start_col, runtime_end_col, runtime_tid_col, nvtx_start_col, nvtx_end_col, nvtx_tid_col])

        if use_four_join:
            print("ðŸ”— NVTXâ†’Runtime ç”¨æ—¶é—´+globalTid å¯¹é½ï¼Œå†ç”¨ correlationId å…³è” Kernel")
            text_join, text_expr = _nvtx_layer_expr("n")
            sql = f"""
            WITH nvtx AS (
              SELECT n.{nvtx_start_col} AS nstart, n.{nvtx_end_col} AS nend, n.{nvtx_tid_col} AS ngtid, {text_expr} AS layer
              FROM NVTX_EVENTS n
              {text_join}
              WHERE n.{nvtx_start_col} IS NOT NULL AND n.{nvtx_end_col} IS NOT NULL AND n.{nvtx_tid_col} IS NOT NULL
            ),
            rt AS (
              SELECT r.{runtime_corr_col} AS rcid, r.{runtime_start_col} AS rstart, r.{runtime_end_col} AS rend, r.{runtime_tid_col} AS rgtid
              FROM {runtime_table} r
              WHERE r.{runtime_corr_col} IS NOT NULL AND r.{runtime_start_col} IS NOT NULL AND r.{runtime_end_col} IS NOT NULL AND r.{runtime_tid_col} IS NOT NULL
            )
            SELECT
              nvtx.layer AS layer,
              COALESCE(si.value, CAST(k.{name_col} AS TEXT)) AS kernel_name,
              ROUND(((k.{end_col} - k.{start_col}))/1e6, 3) AS dur_ms
            FROM rt
            JOIN nvtx ON rt.rgtid = nvtx.ngtid AND rt.rstart >= nvtx.nstart AND rt.rend <= nvtx.nend
            JOIN {ktable} k ON k.{corr_col} = rt.rcid
            LEFT JOIN StringIds si ON k.{name_col} = si.id
            ORDER BY k.{start_col};
            """
        elif corr_col and nvtx_corr_col:
            print("ðŸ”— ä½¿ç”¨ correlationId ä¸‰è¡¨å…³è” NVTX + StringIds + CUPTI kernel")
            text_join, text_expr = _nvtx_layer_expr("n")
            sql = f"""
            WITH nvtx AS (
              SELECT n.{nvtx_corr_col} AS cid, {text_expr} AS layer
              FROM NVTX_EVENTS n
              {text_join}
              WHERE n.{nvtx_corr_col} IS NOT NULL
            )
            SELECT
              nvtx.layer AS layer,
              COALESCE(si.value, CAST(k.{name_col} AS TEXT)) AS kernel_name,
              ROUND(((k.{end_col} - k.{start_col}))/1e6, 3) AS dur_ms
            FROM {ktable} k
            JOIN nvtx ON k.{corr_col} = nvtx.cid
            LEFT JOIN StringIds si ON k.{name_col} = si.id
            ORDER BY k.{start_col};
            """
        else:
            print("ðŸ”— ä½¿ç”¨æ—¶é—´èŒƒå›´å…³è” NVTX_EVENTS ä¸Ž CUPTI kernelsï¼ˆfallbackï¼‰")
            nvtx_start_col = nvtx_start_col or "start"
            nvtx_end_col = nvtx_end_col or "end"
            text_join, text_expr = _nvtx_layer_expr("n")
            sql = f"""
            WITH nvtx AS (
              SELECT n.{nvtx_start_col} AS nstart, n.{nvtx_end_col} AS nend, {text_expr} AS layer
              FROM NVTX_EVENTS n
              {text_join}
              WHERE n.{nvtx_start_col} IS NOT NULL AND n.{nvtx_end_col} IS NOT NULL
            )
            SELECT
              nvtx.layer AS layer,
              COALESCE(si.value, CAST(k.{name_col} AS TEXT)) AS kernel_name,
              ROUND(((k.{end_col} - k.{start_col}))/1e6, 3) AS dur_ms
            FROM {ktable} k
            LEFT JOIN StringIds si ON k.{name_col} = si.id
            JOIN nvtx ON k.{start_col} >= nvtx.nstart AND k.{end_col} <= nvtx.nend
            ORDER BY k.{start_col};
            """
        rows: List[Dict[str, Union[str, float]]] = []
        try:
            for layer, kname, dur_ms in cur.execute(sql):
                rows.append({'layer': layer, 'kernel_name': str(kname or ''), 'dur_ms': float(dur_ms)})
        except Exception as e:
            print(f"âš  layer_kernels æŸ¥è¯¢å¤±è´¥: {e}")
            rows = []
        return rows

    def export_to_json(self, json_path: Union[str, Path]) -> Optional[str]:
        try:
            import json as _json
            data = {
                'layer_kernels': self.layer_kernel_rows,
                'kernels_preview': [ki.__dict__ for ki in self.kernels[:50]],
                'tables': self.tables
            }
            Path(json_path).write_text(_json.dumps(data, ensure_ascii=False, indent=2), encoding='utf-8')
            return str(json_path)
        except Exception:
            return None

    def export_kernel_summary_csv(self, nsys_file: str, base_path: Union[str, Path]) -> Optional[str]:
        if self.sqlite_file:
            out_csv = Path(str(self.sqlite_file)).with_name('layer_kernels.csv')
            return str(out_csv) if out_csv.exists() else None
        return None

    def parse_kernel_summary_csv(self, csv_file: Union[str, Path]) -> List[Dict]:
        p = Path(csv_file)
        if not p.exists():
            return []
        rows = []
        with open(p, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for r in reader:
                rows.append(r)
        return rows

class NsysAnalyzer:
    def __init__(self, parser: NsysParser):
        self.parser = parser

    def analyze(self) -> Dict:
        stats: Dict[str, Dict] = {'kernel_analysis': {}}
        total = len(self.parser.layer_kernel_rows)
        total_ms = sum(float(r.get('dur_ms', 0.0)) for r in self.parser.layer_kernel_rows)
        avg_ms = (total_ms / total) if total else 0.0
        stats['kernel_analysis'] = {
            'total_kernels': total,
            'total_kernel_time': total_ms,
            'avg_kernel_time': avg_ms,
        }
        by_layer: Dict[str, Dict[str, float]] = {}
        for r in self.parser.layer_kernel_rows:
            lay = r.get('layer') or 'Unknown'
            by_layer.setdefault(lay, {'count': 0, 'total_ms': 0.0})
            by_layer[lay]['count'] += 1
            by_layer[lay]['total_ms'] += float(r.get('dur_ms', 0.0))
        stats['by_layer'] = by_layer
        return stats
