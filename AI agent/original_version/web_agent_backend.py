#!/usr/bin/env python3
"""
AI Agent Webåç«¯æœåŠ¡å™¨

åŸºäºFastAPIæ„å»ºçš„WebæœåŠ¡å™¨ï¼Œæ”¯æŒï¼š
1. ç±»ChatGPTçš„å¯¹è¯ç•Œé¢
2. æ–‡ä»¶ä¸Šä¼ å’Œè§£æ
3. å®æ—¶åˆ†æè¿›åº¦æ¨é€
4. RESTful APIæ¥å£

ä½œè€…: AIåŠ©æ‰‹
ç‰ˆæœ¬: 1.0
"""

import os
import json
import asyncio
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import traceback

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, UploadFile, File, Form, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# å¯¼å…¥AI Agentç»„ä»¶
from ai_agent_analyzer import AIAgentAnalyzer, AnalysisRequest
import yaml

app = FastAPI(
    title="AI Agent LLMæ€§èƒ½åˆ†æå™¨",
    description="æ™ºèƒ½çš„å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½åˆ†æWebæœåŠ¡",
    version="1.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶æœåŠ¡
static_dir = Path("static")
if static_dir.exists():
    app.mount("/static", StaticFiles(directory="static"), name="static")

# å…¨å±€å˜é‡
agent = None
active_connections: Dict[str, WebSocket] = {}
analysis_sessions: Dict[str, Dict] = {}

# æ•°æ®æ¨¡å‹
class ChatMessage(BaseModel):
    type: str  # "user", "assistant", "system", "file"
    content: str
    timestamp: datetime
    session_id: Optional[str] = None
    file_info: Optional[Dict] = None

class AnalysisStatus(BaseModel):
    session_id: str
    status: str  # "running", "completed", "error"
    progress: int  # 0-100
    message: str
    results: Optional[Dict] = None

class FileUploadResponse(BaseModel):
    filename: str
    file_id: str
    content: Dict
    suggestions: List[str]

class ConfigFileParser:
    """é…ç½®æ–‡ä»¶è§£æå™¨"""
    
    @staticmethod
    def parse_json_config(content: str) -> Dict:
        """è§£æJSONé…ç½®æ–‡ä»¶"""
        try:
            config = json.loads(content)
            return ConfigFileParser._extract_model_info(config)
        except json.JSONDecodeError as e:
            raise ValueError(f"JSONæ ¼å¼é”™è¯¯: {e}")
    
    @staticmethod
    def parse_yaml_config(content: str) -> Dict:
        """è§£æYAMLé…ç½®æ–‡ä»¶"""
        try:
            config = yaml.safe_load(content)
            return ConfigFileParser._extract_model_info(config)
        except yaml.YAMLError as e:
            raise ValueError(f"YAMLæ ¼å¼é”™è¯¯: {e}")
    
    @staticmethod
    def _extract_model_info(config: Dict) -> Dict:
        """ä»é…ç½®ä¸­æå–æ¨¡å‹ä¿¡æ¯"""
        extracted = {
            "model_info": {},
            "analysis_params": {},
            "hardware_info": {},
            "suggestions": []
        }
        
        # æå–æ¨¡å‹ä¿¡æ¯
        model_fields = ["model_name", "model_path", "model_type", "model_size", 
                       "architecture", "parameters", "precision"]
        
        for field in model_fields:
            if field in config:
                extracted["model_info"][field] = config[field]
        
        # æå–åˆ†æå‚æ•°
        analysis_fields = ["batch_size", "input_len", "output_len", "temperature", 
                          "tp_size", "analysis_type", "profile_steps"]
        
        for field in analysis_fields:
            if field in config:
                extracted["analysis_params"][field] = config[field]
        
        # æå–ç¡¬ä»¶ä¿¡æ¯
        hardware_fields = ["gpu_type", "gpu_count", "memory_gb", "compute_capability",
                          "driver_version", "cuda_version"]
        
        for field in hardware_fields:
            if field in config:
                extracted["hardware_info"][field] = config[field]
        
        # ç”Ÿæˆå»ºè®®
        extracted["suggestions"] = ConfigFileParser._generate_suggestions(extracted)
        
        return extracted
    
    @staticmethod
    def _generate_suggestions(extracted_info: Dict) -> List[str]:
        """åŸºäºé…ç½®ä¿¡æ¯ç”Ÿæˆå»ºè®®"""
        suggestions = []
        
        model_info = extracted_info.get("model_info", {})
        analysis_params = extracted_info.get("analysis_params", {})
        hardware_info = extracted_info.get("hardware_info", {})
        
        # åŸºäºæ¨¡å‹å¤§å°çš„å»ºè®®
        model_size = model_info.get("model_size", "")
        if "7b" in model_size.lower():
            suggestions.append("ğŸ¯ 7Bæ¨¡å‹æ¨è: batch_size=8-16, é€‚åˆå•å¡æ¨ç†")
        elif "13b" in model_size.lower():
            suggestions.append("ğŸ¯ 13Bæ¨¡å‹æ¨è: batch_size=4-8, è€ƒè™‘ä½¿ç”¨tensorå¹¶è¡Œ")
        elif "70b" in model_size.lower():
            suggestions.append("ğŸ¯ 70Bæ¨¡å‹æ¨è: batch_size=1-2, å¿…é¡»ä½¿ç”¨å¤šå¡å¹¶è¡Œ")
        
        # åŸºäºGPUç±»å‹çš„å»ºè®®
        gpu_type = hardware_info.get("gpu_type", "").lower()
        if "a100" in gpu_type:
            suggestions.append("ğŸš€ A100 GPUä¼˜åŒ–: ä½¿ç”¨FP16/BF16ç²¾åº¦, å¯ç”¨Tensor Core")
        elif "h100" in gpu_type:
            suggestions.append("ğŸš€ H100 GPUä¼˜åŒ–: ä½¿ç”¨FP8ç²¾åº¦, å……åˆ†åˆ©ç”¨Transformer Engine")
        elif "v100" in gpu_type:
            suggestions.append("âš ï¸ V100 GPUæé†’: å†…å­˜è¾ƒå°ï¼Œå»ºè®®é™ä½batch_size")
        
        # åŸºäºç²¾åº¦çš„å»ºè®®
        precision = model_info.get("precision", "").lower()
        if "fp32" in precision:
            suggestions.append("ğŸ’¾ FP32ç²¾åº¦æé†’: å†…å­˜å ç”¨è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨FP16")
        elif "int8" in precision:
            suggestions.append("âš¡ INT8é‡åŒ–æ£€æµ‹: æ¨ç†é€Ÿåº¦å¿«ï¼Œä½†å¯èƒ½å½±å“ç²¾åº¦")
        
        # åŸºäºåˆ†æç±»å‹çš„å»ºè®®
        analysis_type = analysis_params.get("analysis_type", "")
        if analysis_type == "ncu":
            suggestions.append("ğŸ”¬ NCUæ·±åº¦åˆ†æ: å…³æ³¨kernelæ•ˆç‡å’Œå†…å­˜å¸¦å®½åˆ©ç”¨ç‡")
        elif analysis_type == "nsys":
            suggestions.append("ğŸ“Š NSyså…¨å±€åˆ†æ: å…³æ³¨timelineå’Œçƒ­ç‚¹kernelè¯†åˆ«")
        
        # é€šç”¨å»ºè®®
        if not suggestions:
            suggestions.append("ğŸ’¡ å»ºè®®å…ˆè¿è¡Œnsysè¿›è¡Œå…¨å±€åˆ†æï¼Œå†é’ˆå¯¹çƒ­ç‚¹è¿›è¡Œncuåˆ†æ")
        
        return suggestions

class ConnectionManager:
    """WebSocketè¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
    
    async def connect(self, websocket: WebSocket, session_id: str):
        """å»ºç«‹WebSocketè¿æ¥"""
        await websocket.accept()
        self.active_connections[session_id] = websocket
        print(f"ğŸ”— WebSocketè¿æ¥å·²å»ºç«‹: {session_id}")
    
    def disconnect(self, session_id: str):
        """æ–­å¼€WebSocketè¿æ¥"""
        if session_id in self.active_connections:
            del self.active_connections[session_id]
            print(f"âŒ WebSocketè¿æ¥å·²æ–­å¼€: {session_id}")
    
    async def send_message(self, session_id: str, message: dict):
        """å‘é€æ¶ˆæ¯ç»™ç‰¹å®šä¼šè¯"""
        if session_id in self.active_connections:
            try:
                await self.active_connections[session_id].send_text(json.dumps(message))
            except Exception as e:
                print(f"å‘é€æ¶ˆæ¯å¤±è´¥ {session_id}: {e}")
                self.disconnect(session_id)
    
    async def broadcast(self, message: dict):
        """å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰è¿æ¥"""
        for session_id in list(self.active_connections.keys()):
            await self.send_message(session_id, message)

manager = ConnectionManager()

@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    global agent
    agent = AIAgentAnalyzer()
    print("ğŸ¤– AI Agent WebæœåŠ¡å™¨å¯åŠ¨å®Œæˆ")

@app.get("/", response_class=HTMLResponse)
async def root():
    """ä¸»é¡µ"""
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>AI Agent LLMæ€§èƒ½åˆ†æå™¨</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body>
        <h1>ğŸ¤– AI Agent LLMæ€§èƒ½åˆ†æå™¨</h1>
        <p>è¯·è®¿é—® <a href="/chat">/chat</a> å¼€å§‹ä½¿ç”¨</p>
        <p>APIæ–‡æ¡£: <a href="/docs">/docs</a></p>
    </body>
    </html>
    """

@app.get("/chat", response_class=HTMLResponse)
async def chat_page():
    """èŠå¤©é¡µé¢"""
    chat_file = Path("static/chat.html")
    if chat_file.exists():
        return chat_file.read_text(encoding='utf-8')
    else:
        return HTMLResponse(
            content="<h1>èŠå¤©é¡µé¢æœªæ‰¾åˆ°</h1><p>è¯·ç¡®ä¿ static/chat.html æ–‡ä»¶å­˜åœ¨</p>",
            status_code=404
        )

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """WebSocketè¿æ¥ç«¯ç‚¹"""
    await manager.connect(websocket, session_id)
    
    try:
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_text()
            message_data = json.loads(data)
            
            # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
            await handle_websocket_message(session_id, message_data)
            
    except WebSocketDisconnect:
        manager.disconnect(session_id)
    except Exception as e:
        print(f"WebSocketé”™è¯¯ {session_id}: {e}")
        manager.disconnect(session_id)

async def handle_websocket_message(session_id: str, message_data: dict):
    """å¤„ç†WebSocketæ¶ˆæ¯"""
    
    message_type = message_data.get("type", "")
    content = message_data.get("content", "")
    
    if message_type == "user_message":
        # ç”¨æˆ·å‘é€åˆ†æè¯·æ±‚
        await process_user_analysis_request(session_id, content)
    
    elif message_type == "ping":
        # å¿ƒè·³æ£€æµ‹
        await manager.send_message(session_id, {
            "type": "pong",
            "timestamp": datetime.now().isoformat()
        })

async def process_user_analysis_request(session_id: str, prompt: str):
    """å¤„ç†ç”¨æˆ·åˆ†æè¯·æ±‚"""
    
    try:
        # å‘é€å¼€å§‹åˆ†ææ¶ˆæ¯
        await manager.send_message(session_id, {
            "type": "assistant_message",
            "content": f"ğŸ”„ å¼€å§‹åˆ†ææ‚¨çš„è¯·æ±‚: {prompt}",
            "timestamp": datetime.now().isoformat()
        })
        
        # è§£ææç¤ºè¯
        await manager.send_message(session_id, {
            "type": "progress",
            "progress": 10,
            "message": "æ­£åœ¨è§£ææç¤ºè¯..."
        })
        
        # å¼‚æ­¥æ‰§è¡Œåˆ†æ
        asyncio.create_task(run_analysis_async(session_id, prompt))
        
    except Exception as e:
        await manager.send_message(session_id, {
            "type": "error",
            "content": f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}",
            "timestamp": datetime.now().isoformat()
        })

async def run_analysis_async(session_id: str, prompt: str):
    """å¼‚æ­¥è¿è¡Œåˆ†æ"""
    
    try:
        # æ›´æ–°è¿›åº¦
        await manager.send_message(session_id, {
            "type": "progress", 
            "progress": 30,
            "message": "æ­£åœ¨é…ç½®åˆ†æå‚æ•°..."
        })
        
        # è¿è¡Œåˆ†æ (è¿™é‡Œéœ€è¦åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡)
        import concurrent.futures
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(agent.analyze_from_prompt, prompt)
            
            # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
            for i in range(40, 90, 10):
                await asyncio.sleep(2)
                await manager.send_message(session_id, {
                    "type": "progress",
                    "progress": i,
                    "message": f"åˆ†æè¿›è¡Œä¸­... {i}%"
                })
            
            # è·å–ç»“æœ
            results = future.result()
        
        # å‘é€å®Œæˆæ¶ˆæ¯
        await manager.send_message(session_id, {
            "type": "progress",
            "progress": 100,
            "message": "åˆ†æå®Œæˆ!"
        })
        
        if 'error' not in results:
            # æˆåŠŸå®Œæˆ
            output_dir = results.get('request', {}).get('output_dir', 'N/A')
            
            response_content = f"""âœ… **åˆ†æå®Œæˆ!**
            
ğŸ“ **ç»“æœç›®å½•**: {output_dir}
ğŸ”¬ **åˆ†æç±»å‹**: {results.get('request', {}).get('analysis_type', 'N/A')}
ğŸ“Š **æ¨¡å‹**: {results.get('request', {}).get('model_name', 'N/A')}

ğŸ¯ **ä¸»è¦å‘ç°**:
- åˆ†æå·²æˆåŠŸå®Œæˆ
- è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°æŒ‡å®šç›®å½•
- å¯æŸ¥çœ‹ç”Ÿæˆçš„å¯è§†åŒ–å›¾è¡¨å’ŒæŠ¥å‘Š

ğŸ’¡ **ä¸‹ä¸€æ­¥å»ºè®®**:
1. æŸ¥çœ‹ç”Ÿæˆçš„timelineå›¾è¡¨
2. åˆ†ææ€§èƒ½ç“¶é¢ˆæŠ¥å‘Š
3. æ ¹æ®å»ºè®®è¿›è¡Œä¼˜åŒ–
"""
            
            await manager.send_message(session_id, {
                "type": "assistant_message",
                "content": response_content,
                "timestamp": datetime.now().isoformat(),
                "results": results
            })
        else:
            # åˆ†æå¤±è´¥
            await manager.send_message(session_id, {
                "type": "error",
                "content": f"âŒ åˆ†æå¤±è´¥: {results['error']}",
                "timestamp": datetime.now().isoformat()
            })
            
    except Exception as e:
        # å¼‚å¸¸å¤„ç†
        await manager.send_message(session_id, {
            "type": "error", 
            "content": f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
            "timestamp": datetime.now().isoformat()
        })
        print(f"åˆ†æå¼‚å¸¸: {traceback.format_exc()}")

@app.post("/upload_config", response_model=FileUploadResponse)
async def upload_config(file: UploadFile = File(...)):
    """ä¸Šä¼ é…ç½®æ–‡ä»¶"""
    
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.filename.endswith(('.json', '.yaml', '.yml')):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒJSONå’ŒYAMLæ ¼å¼æ–‡ä»¶")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        content_str = content.decode('utf-8')
        
        # è§£ææ–‡ä»¶
        if file.filename.endswith('.json'):
            parsed_info = ConfigFileParser.parse_json_config(content_str)
        else:
            parsed_info = ConfigFileParser.parse_yaml_config(content_str)
        
        # ç”Ÿæˆæ–‡ä»¶ID
        file_id = str(uuid.uuid4())
        
        # ä¿å­˜åˆ°ä¸´æ—¶å­˜å‚¨ (ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ•°æ®åº“)
        temp_dir = Path("temp_uploads")
        temp_dir.mkdir(exist_ok=True)
        
        with open(temp_dir / f"{file_id}.json", 'w', encoding='utf-8') as f:
            json.dump(parsed_info, f, indent=2, ensure_ascii=False)
        
        return FileUploadResponse(
            filename=file.filename,
            file_id=file_id,
            content=parsed_info,
            suggestions=parsed_info.get("suggestions", [])
        )
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"æ–‡ä»¶è§£æå¤±è´¥: {str(e)}")

@app.post("/generate_command")
async def generate_command(config_data: Dict[str, Any]):
    """åŸºäºé…ç½®ç”Ÿæˆåˆ†æå‘½ä»¤"""
    
    try:
        # æå–é…ç½®ä¿¡æ¯
        model_info = config_data.get("model_info", {})
        analysis_params = config_data.get("analysis_params", {})
        
        # æ„å»ºæç¤ºè¯
        model_name = model_info.get("model_name", "unknown_model")
        batch_size = analysis_params.get("batch_size", [8])
        input_len = analysis_params.get("input_len", [512])
        output_len = analysis_params.get("output_len", [64])
        analysis_type = analysis_params.get("analysis_type", "auto")
        
        # æ ¼å¼åŒ–batch_sizeç­‰å‚æ•°
        if isinstance(batch_size, list):
            batch_str = ",".join(map(str, batch_size))
        else:
            batch_str = str(batch_size)
        
        if isinstance(input_len, list):
            input_str = ",".join(map(str, input_len))
        else:
            input_str = str(input_len)
        
        if isinstance(output_len, list):
            output_str = ",".join(map(str, output_len))
        else:
            output_str = str(output_len)
        
        # ç”Ÿæˆæç¤ºè¯
        prompt = f"""åˆ†ææ¨¡å‹ {model_name}ï¼Œ
ä½¿ç”¨ {analysis_type} åˆ†æï¼Œ
batch_size: {batch_str}ï¼Œ
input_len: {input_str}ï¼Œ
output_len: {output_str}"""
        
        # æ·»åŠ å…¶ä»–å‚æ•°
        if "temperature" in analysis_params:
            prompt += f"ï¼Œtemperature: {analysis_params['temperature']}"
        
        if "tp_size" in analysis_params and analysis_params["tp_size"] > 1:
            prompt += f"ï¼Œtp_size: {analysis_params['tp_size']}"
        
        return {
            "prompt": prompt,
            "command": f'python ai_agent_analyzer.py prompt "{prompt}"',
            "config_summary": {
                "model": model_name,
                "analysis_type": analysis_type,
                "batch_size": batch_size,
                "input_len": input_len,
                "output_len": output_len
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ç”Ÿæˆå‘½ä»¤å¤±è´¥: {str(e)}")

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "active_connections": len(manager.active_connections),
        "agent_ready": agent is not None
    }

@app.get("/sessions")
async def list_sessions():
    """åˆ—å‡ºæ´»åŠ¨ä¼šè¯"""
    return {
        "active_sessions": list(manager.active_connections.keys()),
        "count": len(manager.active_connections)
    }

if __name__ == "__main__":
    # å¼€å‘ç¯å¢ƒè¿è¡Œ
    uvicorn.run(
        "web_agent_backend:app",
        host="0.0.0.0", 
        port=8000,
        reload=True,
        log_level="info"
    )
